# Formula Verification Report

## Date: December 30, 2025

---

## âœ… All Mathematical Formulas Verified Correct

### 1. Relation-wise Gating Parameter

**Formula from specification:**

```
a âˆˆ â„^|R|
```

where each element `aáµ£` corresponds to one relation r.

**Implementation:** âœ… CORRECT

```python
self.alpha = nn.Embedding(sizes[1], 1)  # sizes[1] = |R|
nn.init.constant_(self.alpha.weight, 0.0)  # Initialize to 0
```

- Shape: (num_relations, 1) âœ“
- Initialization: a = 0 â†’ Ïƒ(0) = 0.5 (neutral baseline) âœ“

---

### 2. Gating Function

**Formula from specification:**

```
G(m, r) = Ïƒ(aáµ£) Â· m + (1 - Ïƒ(aáµ£)) Â· 1
```

**Implementation:** âœ… CORRECT

```python
alpha = torch.sigmoid(self.alpha(x[:, 1].long()))  # Ïƒ(aáµ£)
gate = alpha * m + (1 - alpha) * torch.ones_like(m)
```

**Verification:**

- Ïƒ is sigmoid function âœ“
- m is time embedding vector âœ“
- 1 is ones vector (not scalar) âœ“
- When Î± â†’ 0: G â†’ 1 (static, ignores time) âœ“
- When Î± â†’ 1: G â†’ m (dynamic, full temporal) âœ“

---

### 3. Continuous Time Embedding

**Formula from specification:**

```
m = cos(W Â· t + b)
```

where:

- t âˆˆ [-1, 1] (normalized continuous time)
- W, b âˆˆ â„^d (learnable parameters)
- m âˆˆ â„^d (time embedding)

**Implementation:** âœ… CORRECT

```python
class ContinuousTimeEmbedding(nn.Module):
    def __init__(self, dim: int):
        super().__init__()
        self.W = nn.Parameter(torch.randn(dim) * 0.01)
        self.b = nn.Parameter(torch.zeros(dim))

    def forward(self, t: torch.Tensor):
        return torch.cos(t.unsqueeze(-1) * self.W + self.b)
```

**Verification:**

- Element-wise cosine âœ“
- Broadcasting correct âœ“
- W initialized small (0.01) âœ“
- b initialized zero âœ“

---

### 4. Scoring Function

**Formula from specification:**

```
Ï†(h, r, t, m) = |(h âˆ˜ r^H - t âˆ˜ r^T) âˆ˜ G(m, r)|
```

where:

- âˆ˜ denotes Hadamard product (element-wise multiplication)
- | Â· | denotes L1 norm (sum of absolute values)
- Negative sign for distance â†’ similarity conversion

**Implementation:** âœ… CORRECT

```python
def score(self, x: torch.Tensor):
    h = self.entity_embeddings(x[:, 0].long())
    r_h = self.relation_head(x[:, 1].long())
    t = self.entity_embeddings(x[:, 2].long())
    r_t = self.relation_tail(x[:, 1].long())

    time_continuous = x[:, 3].float()
    m = self.time_encoder(time_continuous)
    alpha = torch.sigmoid(self.alpha(x[:, 1].long()))
    gate = alpha * m + (1 - alpha) * torch.ones_like(m)

    interaction = (h * r_h - t * r_t) * gate  # Hadamard products
    score = -torch.norm(interaction, p=1, dim=-1)  # Negative L1 norm
    return score
```

**Verification:**

- h âˆ˜ r^H: element-wise multiplication âœ“
- t âˆ˜ r^T: element-wise multiplication âœ“
- Result âˆ˜ G(m,r): element-wise multiplication âœ“
- L1 norm: torch.norm(p=1) â‰¡ sum(abs()) âœ“
- Negative sign: converts distance to similarity âœ“

---

### 5. Forward Pass Consistency

**Implementation:** âœ… CORRECT (Fixed)

**Before fix:**

```python
score = -torch.abs(interaction).sum(dim=1)  # Manual L1
```

**After fix:**

```python
score = -torch.norm(interaction, p=1, dim=1)  # Consistent with score()
```

Both implementations are mathematically equivalent:

- `torch.norm(p=1)` = `torch.abs().sum()`
- But using `torch.norm(p=1)` is cleaner and consistent

---

## ğŸ“Š Verification Test Results

### Test 1: Alpha Shape

- Expected: (num_relations, 1)
- Actual: (10, 1)
- **Status: âœ… PASS**

### Test 2: Alpha Initialization

- Expected: ~0.0 (so Ïƒ(0) = 0.5)
- Actual: 0.000000
- **Status: âœ… PASS**

### Test 3: Time Embedding m = cos(WÂ·t + b)

- Max difference: 0.0000000000
- **Status: âœ… PASS**

### Test 4: Gating Formula G(m,r)

- Formula match: 0.0000000000
- When Î±â‰ˆ0, Gâ‰ˆ1: 0.000000
- **Status: âœ… PASS**

### Test 5: Scoring Formula Ï†(h,r,t,m)

- Manual vs Model: 0.0000000000
- **Status: âœ… PASS**

### Test 6: L1 Norm Implementation

- Manual abs.sum: 10.000000
- torch.norm(p=1): 10.000000
- **Status: âœ… PASS**

### Test 7: Negative Sign Convention

- Reasoning verified: distance â†’ similarity
- **Status: âœ… CORRECT**

---

## ğŸ¯ Summary

**All mathematical formulas from the specification are correctly implemented:**

1. âœ… Relation-wise parameter vector a âˆˆ â„^|R|
2. âœ… Gating function G(m,r) = Ïƒ(aáµ£)Â·m + (1-Ïƒ(aáµ£))Â·1
3. âœ… Time embedding m = cos(WÂ·t + b)
4. âœ… Scoring function Ï† = |(hâˆ˜r^H - tâˆ˜r^T)âˆ˜G(m,r)|
5. âœ… L1 norm for distance computation
6. âœ… Negative sign for similarity conversion
7. âœ… Hadamard products (element-wise multiplication)

**Minor fix applied:**

- Changed `torch.abs().sum()` to `torch.norm(p=1)` in forward() for consistency

**No other changes needed - implementation is mathematically correct!**

---

## ğŸš€ Ready for Training

The model implementation perfectly matches the mathematical specification.
You can proceed with training using:

```powershell
cd scripts
.\repreprocess_time.ps1  # Re-normalize to [-1, 1] if not done
.\train_continuous_pairre.ps1
```
